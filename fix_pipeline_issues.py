#!/usr/bin/env python3
"""
Automated Pipeline Issues Fix Script

This script addresses the three major pipeline issues:
1. Step 32 Column Name Issue - rename 'Cluster' to 'cluster_id' in clustering results
2. Missing Period-Specific Data Files - create symlinks for 202510A using 202407A data
3. Timestamped File Dependencies - create generic filename symlinks

Author: Pipeline Team
Date: 2025-10-01
"""

import os
import pandas as pd
import glob
import shutil
from pathlib import Path
import argparse
import json
from datetime import datetime

def log_progress(message):
    """Log progress with timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}")

def fix_step32_column_name_issue():
    """
    Fix Issue 1: Step 32 Column Name Issue
    
    Problem: Step 6 outputs 'Cluster' column, Step 32 expects 'cluster_id'
    Solution: Rename column in clustering results files
    """
    log_progress("üîß FIXING ISSUE 1: Step 32 Column Name Issue")
    
    # Find clustering results files
    clustering_files = [
        "output/clustering_results_spu.csv",
        "output/clustering_results_subcategory.csv", 
        "output/clustering_results_category_agg.csv",
        "output/enhanced_clustering_results.csv"
    ]
    
    fixed_files = []
    
    for file_path in clustering_files:
        if os.path.exists(file_path):
            try:
                # Read the file
                df = pd.read_csv(file_path)
                
                # Check if 'Cluster' column exists and 'cluster_id' doesn't
                if 'Cluster' in df.columns and 'cluster_id' not in df.columns:
                    # Rename the column
                    df = df.rename(columns={'Cluster': 'cluster_id'})
                    
                    # Save back to file
                    df.to_csv(file_path, index=False)
                    log_progress(f"   ‚úÖ Fixed column name in {file_path}")
                    fixed_files.append(file_path)
                    
                elif 'cluster_id' in df.columns:
                    log_progress(f"   ‚úÖ {file_path} already has cluster_id column")
                else:
                    log_progress(f"   ‚ö†Ô∏è  {file_path} has neither 'Cluster' nor 'cluster_id' columns")
                    
            except Exception as e:
                log_progress(f"   ‚ùå Error processing {file_path}: {e}")
        else:
            log_progress(f"   ‚ö†Ô∏è  File not found: {file_path}")
    
    if fixed_files:
        log_progress(f"‚úÖ Issue 1 RESOLVED: Fixed {len(fixed_files)} clustering files")
    else:
        log_progress("‚ö†Ô∏è  Issue 1: No files needed fixing or files not found")
    
    return fixed_files

def create_period_specific_symlinks(target_period="202510A", source_period="202407A"):
    """
    Fix Issue 2: Missing Period-Specific Data Files
    
    Problem: Steps expect 202510A data files that don't exist
    Solution: Create symlinks using 202407A data
    """
    log_progress(f"üîß FIXING ISSUE 2: Missing Period-Specific Data Files ({target_period})")
    
    # Define period-specific file patterns that need symlinks
    period_files = [
        "data/api_data/fast_fish_data_{period}.csv",
        "data/api_data/store_config_{period}.csv", 
        "data/api_data/spu_sales_{period}.csv",
        "data/api_data/category_sales_{period}.csv",
        "output/weather_data/consolidated_weather_{period}.csv",
        "output/stores_with_feels_like_temperature_{period}.csv"
    ]
    
    created_symlinks = []
    
    for file_pattern in period_files:
        target_file = file_pattern.format(period=target_period)
        source_file = file_pattern.format(period=source_period)
        
        # Check if target already exists
        if os.path.exists(target_file):
            log_progress(f"   ‚úÖ {target_file} already exists")
            continue
            
        # Check if source exists
        if os.path.exists(source_file):
            try:
                # Create directory if needed
                os.makedirs(os.path.dirname(target_file), exist_ok=True)
                
                # Create symlink
                os.symlink(os.path.abspath(source_file), target_file)
                log_progress(f"   ‚úÖ Created symlink: {target_file} -> {source_file}")
                created_symlinks.append(target_file)
                
            except Exception as e:
                log_progress(f"   ‚ùå Error creating symlink for {target_file}: {e}")
        else:
            log_progress(f"   ‚ö†Ô∏è  Source file not found: {source_file}")
    
    if created_symlinks:
        log_progress(f"‚úÖ Issue 2 RESOLVED: Created {len(created_symlinks)} period-specific symlinks")
    else:
        log_progress("‚ö†Ô∏è  Issue 2: No symlinks needed or source files not found")
    
    return created_symlinks

def create_timestamped_file_symlinks():
    """
    Fix Issue 3: Timestamped File Dependencies
    
    Problem: Steps expect generic filenames but get timestamped ones
    Solution: Create generic filename symlinks for timestamped files
    """
    log_progress("üîß FIXING ISSUE 3: Timestamped File Dependencies")
    
    # Define timestamped file mappings (generic_name: pattern_to_find)
    timestamped_mappings = {
        # Step 26 expects this generic file
        "output/product_role_classifications.csv": "output/product_role_classifications_*.csv",
        
        # Step 27 expects this generic file  
        "output/price_band_analysis.csv": "output/price_band_analysis_*.csv",
        
        # Step 28 expects these generic files
        "output/gap_analysis_detailed.csv": "output/gap_analysis_detailed_*.csv",
        "output/gap_matrix_summary.json": "output/gap_matrix_summary_*.json",
        
        # Step 31 expects this generic file
        "output/supply_demand_gap_detailed.csv": "output/supply_demand_gap_detailed_*.csv"
    }
    
    created_symlinks = []
    
    for generic_name, pattern in timestamped_mappings.items():
        # Check if generic file already exists
        if os.path.exists(generic_name):
            log_progress(f"   ‚úÖ {generic_name} already exists")
            continue
            
        # Find the most recent timestamped file matching the pattern
        matching_files = glob.glob(pattern)
        
        if matching_files:
            # Sort by modification time, get most recent
            latest_file = max(matching_files, key=os.path.getmtime)
            
            try:
                # Create directory if needed
                os.makedirs(os.path.dirname(generic_name), exist_ok=True)
                
                # Create symlink
                os.symlink(os.path.abspath(latest_file), generic_name)
                log_progress(f"   ‚úÖ Created symlink: {generic_name} -> {latest_file}")
                created_symlinks.append(generic_name)
                
            except Exception as e:
                log_progress(f"   ‚ùå Error creating symlink for {generic_name}: {e}")
        else:
            log_progress(f"   ‚ö†Ô∏è  No timestamped files found matching: {pattern}")
    
    if created_symlinks:
        log_progress(f"‚úÖ Issue 3 RESOLVED: Created {len(created_symlinks)} timestamped file symlinks")
    else:
        log_progress("‚ö†Ô∏è  Issue 3: No symlinks needed or timestamped files not found")
    
    return created_symlinks

def create_fix_report(fixed_files, period_symlinks, timestamped_symlinks, target_period, source_period):
    """Create a comprehensive fix report"""
    
    report = {
        "fix_timestamp": datetime.now().isoformat(),
        "target_period": target_period,
        "source_period": source_period,
        "issues_fixed": {
            "issue_1_column_names": {
                "description": "Step 32 Column Name Issue - 'Cluster' to 'cluster_id'",
                "files_fixed": fixed_files,
                "status": "RESOLVED" if fixed_files else "NO_ACTION_NEEDED"
            },
            "issue_2_period_files": {
                "description": f"Missing Period-Specific Data Files - {target_period} symlinks",
                "symlinks_created": period_symlinks,
                "status": "RESOLVED" if period_symlinks else "NO_ACTION_NEEDED"
            },
            "issue_3_timestamped_files": {
                "description": "Timestamped File Dependencies - generic name symlinks",
                "symlinks_created": timestamped_symlinks,
                "status": "RESOLVED" if timestamped_symlinks else "NO_ACTION_NEEDED"
            }
        },
        "summary": {
            "total_files_fixed": len(fixed_files),
            "total_period_symlinks": len(period_symlinks),
            "total_timestamped_symlinks": len(timestamped_symlinks),
            "all_issues_addressed": len(fixed_files) > 0 or len(period_symlinks) > 0 or len(timestamped_symlinks) > 0
        }
    }
    
    # Save report
    report_file = f"output/pipeline_fix_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs("output", exist_ok=True)
    
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    log_progress(f"üìä Fix report saved to: {report_file}")
    return report

def main():
    """Main execution function"""
    parser = argparse.ArgumentParser(description="Fix Pipeline Issues")
    parser.add_argument("--target-period", default="202510A", 
                       help="Target period for symlinks (default: 202510A)")
    parser.add_argument("--source-period", default="202407A",
                       help="Source period for symlinks (default: 202407A)")
    parser.add_argument("--skip-column-fix", action="store_true",
                       help="Skip column name fix")
    parser.add_argument("--skip-period-fix", action="store_true", 
                       help="Skip period-specific file fix")
    parser.add_argument("--skip-timestamped-fix", action="store_true",
                       help="Skip timestamped file fix")
    parser.add_argument("--dry-run", action="store_true",
                       help="Show what would be done without making changes")
    
    args = parser.parse_args()
    
    log_progress("üöÄ STARTING PIPELINE ISSUES FIX")
    log_progress(f"Target Period: {args.target_period}")
    log_progress(f"Source Period: {args.source_period}")
    
    if args.dry_run:
        log_progress("üîç DRY RUN MODE - No changes will be made")
    
    fixed_files = []
    period_symlinks = []
    timestamped_symlinks = []
    
    # Fix Issue 1: Column Names
    if not args.skip_column_fix:
        if args.dry_run:
            log_progress("üîç DRY RUN: Would check and fix column names in clustering files")
        else:
            fixed_files = fix_step32_column_name_issue()
    else:
        log_progress("‚è≠Ô∏è  Skipping Issue 1: Column name fix")
    
    # Fix Issue 2: Period-Specific Files
    if not args.skip_period_fix:
        if args.dry_run:
            log_progress(f"üîç DRY RUN: Would create period-specific symlinks for {args.target_period}")
        else:
            period_symlinks = create_period_specific_symlinks(args.target_period, args.source_period)
    else:
        log_progress("‚è≠Ô∏è  Skipping Issue 2: Period-specific file fix")
    
    # Fix Issue 3: Timestamped Files
    if not args.skip_timestamped_fix:
        if args.dry_run:
            log_progress("üîç DRY RUN: Would create generic filename symlinks for timestamped files")
        else:
            timestamped_symlinks = create_timestamped_file_symlinks()
    else:
        log_progress("‚è≠Ô∏è  Skipping Issue 3: Timestamped file fix")
    
    # Create comprehensive report (only if not dry run)
    if not args.dry_run:
        report = create_fix_report(fixed_files, period_symlinks, timestamped_symlinks, 
                                  args.target_period, args.source_period)
    
    # Summary
    log_progress("üéâ PIPELINE ISSUES FIX COMPLETED")
    if not args.dry_run:
        log_progress(f"   ‚Ä¢ Column fixes: {len(fixed_files)}")
        log_progress(f"   ‚Ä¢ Period symlinks: {len(period_symlinks)}")
        log_progress(f"   ‚Ä¢ Timestamped symlinks: {len(timestamped_symlinks)}")
        
        total_fixes = len(fixed_files) + len(period_symlinks) + len(timestamped_symlinks)
        if total_fixes > 0:
            log_progress("‚úÖ ALL ISSUES SUCCESSFULLY ADDRESSED")
            log_progress("üöÄ Pipeline should now run without the reported issues!")
        else:
            log_progress("‚ö†Ô∏è  NO ISSUES REQUIRED FIXING (files may already be correct)")
    else:
        log_progress("üîç DRY RUN COMPLETED - Run without --dry-run to apply fixes")

if __name__ == "__main__":
    main()
